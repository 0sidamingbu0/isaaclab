# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
# All rights reserved.
#
# SPDX-License-Identifier: BSD-3-Clause

from __future__ import annotations

import math

import isaaclab.sim as sim_utils
from isaaclab.assets import ArticulationCfg, AssetBaseCfg
from isaaclab.envs import ManagerBasedRLEnvCfg
import isaaclab.envs.mdp as isaaclab_mdp
from isaaclab.managers import EventTermCfg as EventTerm
from isaaclab.managers import ObservationGroupCfg as ObsGroup
from isaaclab.managers import ObservationTermCfg as ObsTerm
from isaaclab.managers import RewardTermCfg as RewTerm
from isaaclab.managers import SceneEntityCfg
from isaaclab.managers import TerminationTermCfg as DoneTerm
from isaaclab.managers import CurriculumTermCfg as CurrTerm
from isaaclab.scene import InteractiveSceneCfg
from isaaclab.sensors import ContactSensorCfg, ImuCfg  # ç§»é™¤äº†RayCasterCfgå’Œpatternsï¼ˆé«˜åº¦æ‰«æç›¸å…³ï¼‰
from isaaclab.terrains import TerrainImporterCfg
from isaaclab.utils import configclass
from isaaclab.utils.assets import ISAAC_NUCLEUS_DIR
from isaaclab.utils.noise import AdditiveUniformNoiseCfg as Unoise

# Import OceanBDX robot configuration
from oceanbdx.assets.oceanusd import OCEAN_ROBOT_CFG

# Import MDP functions
from . import mdp

##
# Scene definition
##


@configclass
class OceanBDXLocomotionSceneCfg(InteractiveSceneCfg):
    """Configuration for the locomotion scene with OceanBDX robot."""

    # ground terrain
    terrain = TerrainImporterCfg(
        prim_path="/World/ground",
        terrain_type="plane",
        terrain_generator=None,
        max_init_terrain_level=5,
        collision_group=-1,
        physics_material=sim_utils.RigidBodyMaterialCfg(
            friction_combine_mode="multiply",
            restitution_combine_mode="multiply",
            static_friction=1.0,
            dynamic_friction=1.0,
        ),
        visual_material=sim_utils.MdlFileCfg(
            mdl_path=f"{ISAAC_NUCLEUS_DIR}/Materials/TilesAiMaterial/TilesAiMaterial.mdl",
            project_uvw=True,
        ),
        debug_vis=False,
    )
    
    # robot
    robot: ArticulationCfg = OCEAN_ROBOT_CFG.replace(prim_path="{ENV_REGEX_NS}/Robot")
    
    # IMU sensor attached to the robot's imu_link
    imu_sensor = ImuCfg(
        prim_path="{ENV_REGEX_NS}/Robot/imu_link",
        update_period=0.005,  # 200 Hz
        debug_vis=True,  # å¯ç”¨IMUå¯è§†åŒ–
    )

    # ã€è¶³éƒ¨æ¥è§¦ä¼ æ„Ÿå™¨ã€‘- åªåœ¨è„šéƒ¨é“¾æ¥(leg_l5/leg_r5)ä¸Šæ£€æµ‹æ¥è§¦åŠ›
    contact_forces_LF = ContactSensorCfg(
        prim_path="{ENV_REGEX_NS}/Robot/leg_l5_link",  # ã€ä¿®æ­£ã€‘åªç›‘æµ‹å·¦è„šæ¥è§¦ï¼Œä¸æ˜¯æ‰€æœ‰å·¦è…¿é“¾æ¥
        update_period=0.005,  # 200 Hz
        history_length=3,  # ã€å¯è°ƒã€‘ä¿å­˜3å¸§å†å²æ•°æ®ï¼Œç”¨äºæ­¥æ€åˆ†æ
        debug_vis=True,  # ã€å¯è°ƒã€‘æ˜¾ç¤ºæ¥è§¦åŠ›å¯è§†åŒ–(ç»¿è‰²çƒ)
    )

    contact_forces_RF = ContactSensorCfg(
        prim_path="{ENV_REGEX_NS}/Robot/leg_r5_link",  # ã€ä¿®æ­£ã€‘åªç›‘æµ‹å³è„šæ¥è§¦ï¼Œä¸æ˜¯æ‰€æœ‰å³è…¿é“¾æ¥
        update_period=0.005,  # 200 Hz
        history_length=3,  # ã€å¯è°ƒã€‘ä¿å­˜3å¸§å†å²æ•°æ®ï¼Œç”¨äºæ­¥æ€åˆ†æ
        debug_vis=True,  # ã€å¯è°ƒã€‘æ˜¾ç¤ºæ¥è§¦åŠ›å¯è§†åŒ–(ç»¿è‰²çƒ)
    )

    # ã€è†ç›–æ¥è§¦ä¼ æ„Ÿå™¨ã€‘- æ£€æµ‹è†ç›–æ˜¯å¦è§¦åœ°ï¼Œç”¨äºç»ˆæ­¢æ¡ä»¶
    contact_forces_knee_L = ContactSensorCfg(
        prim_path="{ENV_REGEX_NS}/Robot/leg_l3_link",  # å·¦è†ç›–é“¾æ¥
        update_period=0.005,  # 200 Hz
        history_length=1,  # åªéœ€è¦å½“å‰å¸§æ•°æ®
        debug_vis=True,  # æ˜¾ç¤ºè†ç›–æ¥è§¦å¯è§†åŒ–
        force_threshold=2.0,  # è†ç›–æ¥è§¦åŠ›é˜ˆå€¼
    )

    contact_forces_knee_R = ContactSensorCfg(
        prim_path="{ENV_REGEX_NS}/Robot/leg_r3_link",  # å³è†ç›–é“¾æ¥
        update_period=0.005,  # 200 Hz
        history_length=1,  # åªéœ€è¦å½“å‰å¸§æ•°æ®
        debug_vis=True,  # æ˜¾ç¤ºè†ç›–æ¥è§¦å¯è§†åŒ–
        force_threshold=2.0,  # è†ç›–æ¥è§¦åŠ›é˜ˆå€¼
    )

    # lights
    light = AssetBaseCfg(
        prim_path="/World/light",
        spawn=sim_utils.DomeLightCfg(color=(0.75, 0.75, 0.75), intensity=3000.0),
    )


##
# MDP settings
##


@configclass
class CommandsCfg:
    """
    é€Ÿåº¦å‘½ä»¤é…ç½® - æ”¯æŒä¸‰é˜¶æ®µè¯¾ç¨‹å­¦ä¹ 
    
    ä¸‰é˜¶æ®µé€Ÿåº¦èŒƒå›´æ¼”åŒ–ï¼š
    - Stage1 (0-30%): 0-0.35 m/s - å­¦ä¹ ç¨³å®šç«™ç«‹å’ŒåŸºç¡€æ­¥æ€
    - Stage2 (30-70%): 0-0.5 m/s - å½¢æˆå®Œæ•´æ­¥æ€æ¨¡å¼
    - Stage3 (70-100%): 0-0.74 m/s - ä¼˜åŒ–æ­¥æ€è´¨é‡å’Œé€Ÿåº¦
    
    æ³¨ï¼šè®­ç»ƒæ—¶éœ€è¦åŠ¨æ€è°ƒæ•´lin_vel_xèŒƒå›´ï¼Œå‚è€ƒtraining_curriculum.py
    """

    base_velocity = mdp.UniformVelocityCommandCfg(
        asset_name="robot",
        resampling_time_range=(15.0, 20.0),  # å‘½ä»¤é‡æ–°é‡‡æ ·é—´éš”ï¼ŒStage1å¯ç”¨è¾ƒé•¿å€¼ä¿æŒç¨³å®š
        rel_standing_envs=0.2,  # ğŸ¯ Stage1æå‡åˆ°20%é™æ­¢ç¯å¢ƒï¼Œå­¦ä¹ ç¨³å®šç«™ç«‹
        rel_heading_envs=0.0,   # å…³é—­æœå‘å‘½ä»¤ï¼Œä¸“æ³¨ç›´çº¿è¡Œèµ°
        heading_command=False,
        heading_control_stiffness=1.0,
        debug_vis=True,
        ranges=mdp.UniformVelocityCommandCfg.Ranges(
            # ğŸ¯ Stage1åˆå§‹èŒƒå›´ï¼šåªè®­ç»ƒä½é€Ÿå‰è¿› (0-0.35 m/s)
            # è®­ç»ƒè„šæœ¬éœ€è¦åŠ¨æ€è°ƒæ•´æ­¤èŒƒå›´ï¼š
            # - Stage2: (0.0, 0.5)
            # - Stage3: (0.0, 0.74)
            lin_vel_x=(0.0, 0.35),   # ï¿½ å…³é”®ï¼šä»Disney BDXå‚è€ƒé€Ÿåº¦0.35m/så¼€å§‹
            lin_vel_y=(-0.1, 0.1),   # ğŸ¯ Stage1é™åˆ¶ä¾§ç§»ï¼ŒStage3å†æ”¾å®½åˆ°(-0.3, 0.3)
            ang_vel_z=(-0.3, 0.3),   # ğŸ¯ Stage1é™åˆ¶æ—‹è½¬ï¼ŒStage3å†æ”¾å®½åˆ°(-0.5, 0.5)
            heading=(-math.pi, math.pi),
        ),
    )


@configclass
class ActionsCfg:
    """ã€åŠ¨ä½œç©ºé—´é…ç½®ã€‘- æ§åˆ¶æœºå™¨äººå…³èŠ‚è¿åŠ¨èŒƒå›´"""

    # ã€å…³èŠ‚ä½ç½®æ§åˆ¶é…ç½®ã€‘
    joint_pos = mdp.JointPositionActionCfg(
        asset_name="robot",
        joint_names=["leg_.*", "neck_.*"],  # æ§åˆ¶çš„å…³èŠ‚ï¼šè…¿éƒ¨å’Œé¢ˆéƒ¨å…³èŠ‚
        scale=0.5,  # ã€é‡è¦å¯è°ƒã€‘åŠ¨ä½œå¹…åº¦ç¼©æ”¾(0-1)ï¼Œ0.25=25%å…³èŠ‚èŒƒå›´ï¼Œå‡å°å¹…åº¦ä½¿åŠ¨ä½œæ›´å¹³ç¨³
        use_default_offset=True,  # ã€å¯è°ƒã€‘æ˜¯å¦ä½¿ç”¨é»˜è®¤å§¿æ€ä½œä¸ºåç§»åŸºå‡†
    )


@configclass
class ObservationsCfg:
    """Observation specifications for the MDP."""

    @configclass
    class PolicyCfg(ObsGroup):
        """Observations for policy group."""

        # ã€IMUä¼ æ„Ÿå™¨è§‚æµ‹æ•°æ®ã€‘- å®Œå…¨åŸºäºçœŸå®IMUè¾“å‡ºï¼Œç¡®ä¿è®­ç»ƒéƒ¨ç½²ä¸€è‡´æ€§
        
        # âœ… IMUè§’é€Ÿåº¦ï¼ˆé™€èºä»ªï¼‰- ä¸å®é™…ç¡¬ä»¶åŒ¹é…
        base_ang_vel = ObsTerm(
            func=mdp.imu_angular_velocity,  # IMUé™€èºä»ª3è½´è§’é€Ÿåº¦
            params={"sensor_cfg": SceneEntityCfg("imu_sensor")},
            noise=Unoise(n_min=-0.2, n_max=0.2)
        )
        # âœ… é‡åŠ›æŠ•å½± - çº¯é‡åŠ›æ–¹å‘ï¼Œä¸å«è¿åŠ¨åŠ é€Ÿåº¦å†²å‡»
        # è®­ç»ƒï¼šä½¿ç”¨robotå§¿æ€è®¡ç®—é‡åŠ›æŠ•å½±ï¼ˆå‡†ç¡®ä¸”ç¨³å®šï¼‰
        # éƒ¨ç½²ï¼šä½¿ç”¨IMUå§¿æ€+ä½é€šæ»¤æ³¢è®¡ç®—é‡åŠ›æŠ•å½±
        # OceanBDXåæ ‡ç³»ï¼šç›´ç«‹[0,0,+9.81], å‰å€¾[+9.81,0,+xxx], å·¦å€¾[0,+9.81,+xxx]
        projected_gravity = ObsTerm(
            func=mdp.projected_gravity,  # ğŸ”§ æ”¹ç”¨çº¯é‡åŠ›æŠ•å½±ï¼Œé¿å…è¿åŠ¨å†²å‡»å™ªå£°
            params={"asset_cfg": SceneEntityCfg("robot")},
            noise=Unoise(n_min=-0.05, n_max=0.05)  # ğŸ”§ å‡å°å™ªå£°ï¼Œå› ä¸ºé‡åŠ›æ›´ç¨³å®š
        )
        
        # âŒ ç§»é™¤å››å…ƒæ•°è§‚æµ‹ - éƒ¨ç½²æ—¶ä¸éœ€è¦ï¼Œé‡åŠ›æŠ•å½±å·²ç»åŒ…å«å§¿æ€ä¿¡æ¯
        # base_quat_w = ObsTerm(
        #     func=mdp.imu_quaternion,
        #     params={"sensor_cfg": SceneEntityCfg("imu_sensor")}
        # )

        # Joint states
        joint_pos_rel = ObsTerm(
            func=isaaclab_mdp.joint_pos_rel,
            noise=Unoise(n_min=-0.01, n_max=0.01)
        )
        joint_vel_rel = ObsTerm(
            func=isaaclab_mdp.joint_vel_rel,
            noise=Unoise(n_min=-1.5, n_max=1.5)
        )
        # ã€æ–°å¢ã€‘å…³èŠ‚è½¬çŸ©åé¦ˆ - æä¾›å®é™…ç”µæœºè¾“å‡ºè½¬çŸ©ä¿¡æ¯ï¼Œå¢å¼ºæ¥è§¦æ„ŸçŸ¥å’ŒåŠ›æ§èƒ½åŠ›
        joint_torques = ObsTerm(
            func=mdp.joint_torques_obs,  # éœ€è¦åˆ›å»ºè¿™ä¸ªè§‚æµ‹å‡½æ•°
            noise=Unoise(n_min=-0.05, n_max=0.05)
        )

        # Commands
        velocity_commands = ObsTerm(func=mdp.generated_commands, params={"command_name": "base_velocity"})

        # Actions
        last_actions = ObsTerm(func=mdp.last_action)

        # ğŸ†• ã€è‡ªé€‚åº”æ­¥æ€ç›¸ä½è§‚æµ‹ã€‘- æ ¹æ®é€Ÿåº¦åŠ¨æ€è°ƒæ•´æœŸæœ›æ­¥æ€å‚æ•°
        # 9ç»´è§‚æµ‹ï¼š6ä¸ªsin/coså¤šé¢‘ç‡ç¼–ç  + phase_rate + desired_stride + desired_clearance
        # ä¸çœŸæœºéƒ¨ç½²å®Œå…¨ä¸€è‡´ï¼Œæä¾›æ˜¾å¼çš„æ—¶é—´/ç›¸ä½ä¿¡æ¯
        adaptive_phase = ObsTerm(
            func=mdp.adaptive_gait_phase_observation
            # æ— éœ€å‚æ•°ï¼Œè‡ªåŠ¨ä»env.phase_managerè·å–
        )

        # Height scan for terrain awareness - æ³¨é‡Šï¼šéƒ¨ç½²æ—¶å¦‚æœæ²¡æœ‰é«˜åº¦æ‰«æä¼ æ„Ÿå™¨åˆ™ç§»é™¤æ­¤è§‚æµ‹
        # height_scan = ObsTerm(
        #     func=mdp.height_scan,
        #     params={"sensor_cfg": SceneEntityCfg("height_scanner")},
        #     noise=Unoise(n_min=-0.1, n_max=0.1),
        #     clip=(-1.0, 1.0),
        # )

        def __post_init__(self):
            self.enable_corruption = True
            self.concatenate_terms = True

    # observation groups
    policy: PolicyCfg = PolicyCfg()


@configclass
class EventsCfg:
    """Configuration for events."""

    # Reset robot joints with some randomization
    reset_robot_joints = EventTerm(
        func=mdp.reset_joints_by_scale,
        mode="reset",
        params={
            "position_range": (0.5, 1.5),
            "velocity_range": (0.0, 0.0),
        },
    )

    # Reset robot base with randomization
    reset_base = EventTerm(
        func=mdp.reset_root_state_uniform,
        mode="reset",
        params={
            "pose_range": {"x": (-0.5, 0.5), "y": (-0.5, 0.5), "yaw": (-3.14, 3.14)},
            "velocity_range": {
                "x": (-0.5, 0.5),
                "y": (-0.5, 0.5),
                "z": (-0.5, 0.5),
                "roll": (-0.5, 0.5),
                "pitch": (-0.5, 0.5),
                "yaw": (-0.5, 0.5),
            },
        },
    )

    # Add random forces to test robustness
    push_robot = EventTerm(
        func=mdp.push_by_setting_velocity,
        mode="interval",
        interval_range_s=(10.0, 15.0),
        params={"velocity_range": {"x": (-1.5, 1.5), "y": (-1.5, 1.5)}},
    )


@configclass
class RewardsCfg:
    """
    ğŸ¯ Disney BDXè‡ªé€‚åº”å¥–åŠ±ç³»ç»Ÿ - 17ä¸ªæ ¸å¿ƒå¥–åŠ±å‡½æ•°
    é…åˆ4é˜¶æ®µè¯¾ç¨‹å­¦ä¹  (training_curriculum.py)
    æ‰€æœ‰å¥–åŠ±å‡½æ•°æ¥è‡ª adaptive_rewards.py
    å‚è€ƒ: Disney BDXè®­ç»ƒæŒ‡å—, legged_gym, walk-these-ways
    """

    # ============================================================================
    # ã€ä»»åŠ¡å¥–åŠ±ã€‘(2ä¸ª) - è®©æœºå™¨äººè·Ÿè¸ªé€Ÿåº¦æŒ‡ä»¤
    # ============================================================================
    
    velocity_tracking = RewTerm(
        func=mdp.reward_velocity_tracking_exp,
        weight=2.0,  # ä¸»å¯¼å¥–åŠ±,è¯¾ç¨‹ä¼šåŠ¨æ€è°ƒæ•´
        params={"command_name": "base_velocity", "std": 0.5}
    )
    
    angular_velocity_tracking = RewTerm(
        func=mdp.reward_angular_velocity_tracking,
        weight=1.0,  # æ¬¡è¦ä»»åŠ¡å¥–åŠ±
        params={"command_name": "base_velocity", "std": 0.5}
    )

    # ============================================================================
    # ã€ç¨³å®šæ€§çº¦æŸã€‘(2ä¸ª) - ä¿æŒç›´ç«‹ä¸æ‘”å€’
    # ============================================================================
    
    orientation_penalty = RewTerm(
        func=mdp.reward_orientation_penalty,
        weight=-1.0  # Stage 0ä¼šæå‡åˆ°-100
    )
    
    base_height_tracking = RewTerm(
        func=mdp.reward_base_height_tracking,
        weight=0.8,  # Stage 0ä¼šæå‡åˆ°15.0
        params={"target_height": 0.35, "std": 0.1}  # é™ä½ç›®æ ‡é«˜åº¦å‡å°‘è†ç›–è¿‡ç›´
    )

    # ============================================================================
    # ã€æ­¥æ€è´¨é‡ã€‘(4ä¸ª) - ğŸ”‘ æ ¸å¿ƒé˜²ä½œå¼Šæœºåˆ¶
    # ============================================================================
    
    # â­ è‡ªé€‚åº”äº¤æ›¿æ¥è§¦ - é˜²æ­¢æŒ¯åŠ¨ä½œå¼Š (æ”¹è¿›ç‰ˆ:æ”¯æŒè¿‡æ¸¡ç›¸)
    feet_alternating_contact = RewTerm(
        func=mdp.reward_feet_alternating_contact,
        weight=0.0,  # Stage 1: 0.3, Stage 2: 1.0, Stage 3: 0.8
        params={"threshold": 1.0}
    )
    
    # ğŸ†• é‡å¿ƒè½¬ç§»å¥–åŠ± - é¼“åŠ±å•è…¿æ”¯æ’‘å’ŒæŠ¬è…¿è¿ˆæ­¥
    weight_transfer = RewTerm(
        func=mdp.reward_weight_transfer,
        weight=0.0,  # Stage 1: 0.5, Stage 2: 1.0, Stage 3: 1.0
        params={"threshold": 1.0}
    )
    
    # è‡ªé€‚åº”æ­¥é•¿è·Ÿè¸ª
    stride_length_tracking = RewTerm(
        func=mdp.reward_stride_length_tracking,
        weight=0.0  # Stage 1: 0.2, Stage 2: 0.8, Stage 3: 0.6
    )
    
    # è‡ªé€‚åº”æŠ¬è„šé«˜åº¦
    foot_clearance = RewTerm(
        func=mdp.reward_foot_clearance,
        weight=0.0,  # Stage 1: 0.2, Stage 2: 0.6, Stage 3: 0.4
        params={"threshold": 1.0}
    )

    # ============================================================================
    # ã€å®‰å…¨çº¦æŸã€‘(3ä¸ª) - é˜²æ­¢å±é™©åŠ¨ä½œ
    # ============================================================================
    
    # æƒ©ç½šè†ç›–ã€èº¯å¹²æ¥è§¦åœ°é¢
    undesired_contacts = RewTerm(
        func=mdp.reward_undesired_contacts,
        weight=-5.0,  # Stage 0: -5.0, Stage 3: -2.0
        params={"threshold": 1.0}
    )
    
    # å…³èŠ‚é™ä½æƒ©ç½š
    joint_limits_penalty = RewTerm(
        func=mdp.reward_joint_limits_penalty,
        weight=-0.1,  # é¿å…è¿‡åº¦ä¸»å¯¼æ€»å¥–åŠ±
        params={"soft_limit_ratio": 0.9}
    )
    
    # æ”¯æ’‘è…¿æ»‘åŠ¨æƒ©ç½š
    feet_slip_penalty = RewTerm(
        func=mdp.reward_feet_slip_penalty,
        weight=-1.0,  # Stage 1: -1.0, Stage 2: -1.5, Stage 3: -2.0
        params={"threshold": 1.0}
    )

    # ============================================================================
    # ã€èƒ½è€—ä¸å¹³æ»‘æ€§ã€‘(4ä¸ª) - ğŸ”‘ é˜²é«˜é¢‘æŒ¯åŠ¨ä½œå¼Š
    # ============================================================================
    
    # â­ åŠ¨ä½œå¹³æ»‘æ€§ - é˜²æ­¢é«˜é¢‘æŒ¯åŠ¨çš„å…³é”®
    action_smoothness = RewTerm(
        func=mdp.reward_action_smoothness,
        weight=-0.001  # Stage 1: -0.001, Stage 2: -0.01, Stage 3: -0.05
    )
    
    # å…³èŠ‚åŠ›çŸ©æƒ©ç½šï¼ˆèƒ½è€—ï¼‰
    joint_torque_penalty = RewTerm(
        func=mdp.reward_joint_torque_penalty,
        weight=-1e-6  # Stage 1: -1e-6, Stage 2: -5e-5, Stage 3: -1e-4
    )
    
    # â­ å…³èŠ‚åŠ é€Ÿåº¦æƒ©ç½š - é˜²æ­¢å‰§çƒˆè¿åŠ¨
    joint_acceleration = RewTerm(
        func=mdp.reward_joint_acceleration_penalty,
        weight=-1e-8  # Stage 1: -1e-8, Stage 2: -2.5e-7, Stage 3: -1e-6
    )
    
    # å…³èŠ‚é€Ÿåº¦æƒ©ç½š
    joint_velocity_penalty = RewTerm(
        func=mdp.reward_joint_velocity_penalty,
        weight=-1e-5  # Stage 1: -1e-5, Stage 2: -5e-4, Stage 3: -1e-3
    )

    # ============================================================================
    # ã€ç»ˆæ­¢æƒ©ç½šã€‘(1ä¸ª) - ä¸¥å‰æƒ©ç½šæ‘”å€’
    # ============================================================================
    
    termination_penalty = RewTerm(
        func=mdp.reward_termination_penalty,
        weight=1.0  # å‡½æ•°å†…éƒ¨å·²ä¹˜ä»¥-100ï¼Œæ€»æƒé‡-100 to -200
    )


@configclass
class TerminationsCfg:
    """ã€ç»ˆæ­¢æ¡ä»¶é…ç½®ã€‘- å†³å®šä½•æ—¶ç»“æŸè®­ç»ƒepisode"""

    # ã€è‡ªåŠ¨ç»ˆæ­¢ã€‘æ—¶é—´åˆ°è¾¾episode_length_såè‡ªåŠ¨ç»“æŸ
    time_out = DoneTerm(func=mdp.time_out, time_out=True)
    # ã€å¯è°ƒã€‘æœºå™¨äººæ‘”å€’é«˜åº¦æ£€æµ‹
    base_height = DoneTerm(
        func=mdp.base_height,
        params={"minimum_height": 0.15, "asset_cfg": SceneEntityCfg("robot")},  # ğŸ”§ Stage 0: æ”¾å®½åˆ°0.15mï¼Œé¿å…è¿‡æ—©ç»ˆæ­¢æ¢ç´¢
    )
    # ã€é‡è¦å¯è°ƒã€‘æœºå™¨äººå€¾å€’è§’åº¦æ£€æµ‹
    base_orientation = DoneTerm(
        func=mdp.bad_orientation,
        params={"limit_angle": math.pi / 3, "asset_cfg": SceneEntityCfg("robot")},  # ğŸ”§ ä¿®å¤ï¼šä»30åº¦æ”¾å®½åˆ°60åº¦ï¼Œç»™æœºå™¨äººæ›´å¤šå­¦ä¹ ç©ºé—´
    )
    # ã€æ–°å¢ã€‘è†ç›–è§¦åœ°ç»ˆæ­¢ - é˜²æ­¢æœºå™¨äººè·ªå€’æˆ–æ‘”å€’æ—¶è†ç›–æ’å‡»åœ°é¢
    # knee_contact = DoneTerm(
    #     func=mdp.knee_ground_contact,
    #     params={
    #         "threshold": 5.0,  # è†ç›–æ¥è§¦åŠ›é˜ˆå€¼(N)
    #     },
    # )


@configclass
class CurriculumCfg:
    """Curriculum terms for the MDP."""
    
    # æš‚æ—¶ç¦ç”¨è¯¾ç¨‹å­¦ä¹ ä»¥ç®€åŒ–é…ç½®
    pass


##
# Environment configuration
##


@configclass
class OceanBDXLocomotionEnvCfg(ManagerBasedRLEnvCfg):
    """Configuration for the OceanBDX locomotion environment."""

    # ã€åœºæ™¯è®¾ç½®ã€‘
    scene: OceanBDXLocomotionSceneCfg = OceanBDXLocomotionSceneCfg(
        num_envs=4096,  # ã€é‡è¦å¯è°ƒã€‘å¹¶è¡Œç¯å¢ƒæ•°é‡ï¼Œ4096ä¸ªæœºå™¨äººåŒæ—¶è®­ç»ƒï¼Œè¶Šå¤šè¶Šå¿«ä½†æ˜¾å­˜è¦æ±‚é«˜
        env_spacing=2.5  # ã€å¯è°ƒã€‘ç¯å¢ƒé—´è·2.5ç±³ï¼Œé˜²æ­¢æœºå™¨äººç¢°æ’
    )
    # Basic settings
    observations: ObservationsCfg = ObservationsCfg()
    actions: ActionsCfg = ActionsCfg()
    commands: CommandsCfg = CommandsCfg()
    # MDP settings
    rewards: RewardsCfg = RewardsCfg()
    terminations: TerminationsCfg = TerminationsCfg()
    events: EventsCfg = EventsCfg()
    curriculum: CurriculumCfg = CurriculumCfg()

    def __post_init__(self):
        """ã€ç¯å¢ƒåˆå§‹åŒ–åé…ç½®ã€‘- å…³é”®è®­ç»ƒå‚æ•°"""
        # ã€é‡è¦å¯è°ƒã€‘åŸºç¡€è®¾ç½®
        self.decimation = 4  # æ§åˆ¶é¢‘ç‡åˆ†é¢‘ï¼Œ4=50Hzæ§åˆ¶é¢‘ç‡(200Hz/4)
        self.episode_length_s = 35.0  # ã€å…³é”®å¯è°ƒã€‘å•æ¬¡è®­ç»ƒæ—¶é•¿35ç§’ï¼Œå½±å“å­¦ä¹ å¤æ‚è¡Œä¸ºçš„æ—¶é—´
        # ã€å¯è°ƒã€‘ä»¿çœŸè®¾ç½®
        self.sim.dt = 0.005  # ä»¿çœŸæ­¥é•¿=200Hzï¼Œè¶Šå°è¶Šç²¾ç¡®ä½†è¶Šæ…¢
        self.sim.physics_material = self.scene.terrain.physics_material

        # ============================================================================
        # ğŸ”‘ è‡ªé€‚åº”æ­¥æ€ç³»ç»Ÿåˆå§‹åŒ–æ ‡è®°
        # ============================================================================
        # æ³¨ï¼šAdaptivePhaseManageréœ€è¦åœ¨ç¯å¢ƒæ„é€ æ—¶æ‰‹åŠ¨åˆ›å»ºå¹¶é™„åŠ åˆ°envå®ä¾‹
        # ç¤ºä¾‹ä»£ç ï¼ˆéœ€æ·»åŠ åˆ°ç¯å¢ƒç±»çš„__init__æ–¹æ³•ï¼‰ï¼š
        #
        #   from oceanbdx.tasks.manager_based.oceanbdx_locomotion.mdp import AdaptivePhaseManager
        #
        #   self.phase_manager = AdaptivePhaseManager(
        #       num_envs=self.num_envs,
        #       dt=self.step_dt,  # æ§åˆ¶æ—¶é—´æ­¥ = decimation * sim.dt
        #       device=self.device
        #   )
        #
        # æ¯ä¸ªä»¿çœŸæ­¥éœ€è¦æ›´æ–°ï¼š
        #   self.phase_manager.update(self.robot.data.root_lin_vel_w[:, :2])
        #
        # è§‚æµ‹å’Œå¥–åŠ±å‡½æ•°ä¼šè‡ªåŠ¨ä»env.phase_managerè·å–å‚æ•°
        # ============================================================================
        
        # update sensor update periods
        # we tick all the sensors based on the smallest update period (physics dt)
        # if self.scene.height_scanner is not None:  # æ³¨é‡Šï¼šé«˜åº¦æ‰«æä¼ æ„Ÿå™¨å·²ç§»é™¤
        #     self.scene.height_scanner.update_period = self.decimation * self.sim.dt
        if self.scene.contact_forces_LF is not None:
            self.scene.contact_forces_LF.update_period = self.sim.dt
        if self.scene.contact_forces_RF is not None:
            self.scene.contact_forces_RF.update_period = self.sim.dt
        if self.scene.imu_sensor is not None:
            self.scene.imu_sensor.update_period = self.sim.dt
        # ã€æ–°å¢ã€‘è†ç›–æ¥è§¦ä¼ æ„Ÿå™¨æ›´æ–°é…ç½®
        if self.scene.contact_forces_knee_L is not None:
            self.scene.contact_forces_knee_L.update_period = self.sim.dt
        if self.scene.contact_forces_knee_R is not None:
            self.scene.contact_forces_knee_R.update_period = self.sim.dt


@configclass
class OceanBDXLocomotionEnvCfg_PLAY(OceanBDXLocomotionEnvCfg):
    """Configuration for the OceanBDX locomotion environment for play mode."""

    def __post_init__(self):
        # post init of parent
        super().__post_init__()

        # make a smaller scene for play
        self.scene.num_envs = 50
        self.scene.env_spacing = 2.5
        # spawn the robot randomly in the grid (instead of their terrain levels)
        self.scene.terrain.max_init_terrain_level = None
        # reduce the number of terrains to save memory
        if self.scene.terrain.terrain_generator is not None:
            self.scene.terrain.terrain_generator.num_rows = 5
            self.scene.terrain.terrain_generator.num_cols = 5
            self.scene.terrain.terrain_generator.curriculum = False

        # disable randomization for play
        self.observations.policy.enable_corruption = False
        # remove random pushing event
        self.events.base_external_force_torque = None
        self.events.push_robot = None
